---
title: "Met_Diet_129"
author: "Qi Yan"
date: "8/21/2019"
output: 
  html_document:
    toc: TRUE # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
    number_sections: FALSE
    theme: united  
    highlight: tango
    df_print: paged
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(xlsx)
library(doParallel)
library(ggridges)
library(ggplot2)
library(viridis)
library(hrbrthemes)
library(gridExtra)

options(stringsAsFactors = FALSE)
```

# Data Preprocessing

## Import Data

```{r import data, echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
setwd("/Users/qiyan/Dropbox/PARENTs")
met_raw <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Raw Data/all_mets_corrected_exclude_where_std_low.xlsx", sheetName = "Corrected", header = T)
met_raw <- met_raw[which(met_raw$C_Label == 0), -2]
met_raw <- met_raw[,order(colnames(met_raw))]

key <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Raw Data/PARENTs Sample Guide.xlsx", sheetIndex = 2, header = T)
met_class <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Raw Data/Metabolite_list_category.xlsx", sheetIndex = 1, header = T)
pheno_raw <- read.csv(file = "/Users/qiyan/Dropbox/PARENTs/Raw Data/PARENTs_KeyVariables_190403.csv", header = T)
nut_raw <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Raw Data/dietcalc_results_20190621.results_IDR.xlsx", sheetIndex = 1, header = T)

# Link Christofk_ID with Subject_ID
temp_ID <- data.frame(colnames(met_raw)[-1]); colnames(temp_ID) <- "Christofk_ID"
temp_ID <- merge(temp_ID, key, by = "Christofk_ID")
colnames(met_raw) <- c("Compound", temp_ID$Subject_ID); rownames(met_raw) <- met_raw$Compound

# Create clean datasets for downstream analyses
met <- data.frame(t(met_raw[,-1])); met <- cbind(rownames(met), met)
colnames(met)[1] <- "Subject_ID"

pheno <- pheno_raw[which(pheno_raw$Subject_ID %in% met$Subject_ID),] # PJR81X, PIM84B, PDD77V couldn't find a match

nut <- nut_raw[which(nut_raw$PARENTs.ID %in% met$Subject_ID),]

save(met, pheno, nut, met_class, file = "/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_raw.RData")
```

## Quality Control

Here is Ernst's reply: 

So original: the raw peak areas of metabolites and their isotopomers outputed by the programs no normalization or anything;

corrected: the peak areas of the isotopomers for each metabolite corrected for the natural abundance of C13 ;

PoolAfterDF: the sum of all the peak areas across all the isotopomers for a specific metabolite;

Trifluoromethanosulfate is the standard I added. The same amount is added to all samples so it should have the same peak area. It is not necessary but can be helpeful to normalize to it so that you reduce the effects of machine performance drift throughout the runs.

### Distribution of raw intensity

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 15, fig.width = 15}
load("/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_raw.RData")
met_raw_stat <- data.frame(colnames(met[,-1])); colnames(met_raw_stat)[1] <- "metabolite"
met_raw_stat$mean <- apply(met[,-1], 2, mean); met_raw_stat$sd <- apply(met[,-1], 2, sd)
met_raw_stat$rsd <- met_raw_stat$sd/met_raw_stat$mean
met_raw_stat <- met_raw_stat[order(-met_raw_stat$rsd),]
met_raw_stat[1:10,]
```

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 15, fig.width = 15}
ggplot(stack(met[,-1]), aes(x = values, y = ind, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Distribution of the raw intensity of metabolites', x = "Intensity", y = "Metabolites") +
  theme_ipsum() +
  theme(
    legend.position="none",
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  )

ggplot(stack(subset(met, select = -c(Subject_ID, trifluoromethanosulfate))), aes(x = values, y = ind, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Distribution of the raw intensity of metabolites \n w/o trifluoromethanosulfate', x = "Intensity", y = "Metabolites") +
  theme_ipsum() +
  theme(
    legend.position="none",
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  )
```

### Missing value

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
met_missing <- data.frame(colnames(met[,-1]))
met_missing$num_missing <- apply(met[,-1], 2, function(x) sum(x==0))
met_missing$percent_missing <- round(met_missing$num_missing/129*100,2)
colnames(met_missing)[1] <- "metabolite"
met_missing <- met_missing[order(-met_missing$num_missing),]
met_missing[which(met_missing$num_missing!=0),]
```

Impute missing value (0) with half of the minimum positive value in the original data.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
met_impute <- met; met_impute[met_impute==0] <- NA
halfdatmin <- min(met_impute[,-1], na.rm = TRUE)*0.5
met_impute[is.na(met_impute)] <- halfdatmin
```

### Batch Effect

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
batch <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Input/met_129_metaboanalyst.xlsx", sheetIndex = 1, header = T); batch <- batch[,1:2]
batch_impute <- merge(batch, met_impute, by = "Subject_ID")
batch_pca <- prcomp(batch_impute[,3:ncol(batch_impute)], center = TRUE, scale. = TRUE)

ggbiplot::ggbiplot(batch_pca, ellipse=FALSE,  groups=batch_impute$Batch)
```

Correlation between top 5 PCs and batchs.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
batch_cor <- data.frame(PCs = colnames(batch_pca$x[,1:5]))
batch_cor$corr <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_impute$Batch)))$estimate)
batch_cor$P_value <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_impute$Batch)))$p.value)

batch_cor
```

Control for batch effect using combat.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
met_norm <- subset(met_impute, select = -c(trifluoromethanosulfate))
# batch <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Input/met_129_metaboanalyst.xlsx", sheetIndex = 1, header = T); batch <- batch[,1:2]
met_norm <- merge(batch, met_norm, by = "Subject_ID")
rownames(met_norm) <- met_norm$Subject_ID

met_norm <- sva::ComBat(dat=t(met_norm[,3:ncol(met_norm)]), batch=met_norm$Batch, mod=NULL, par.prior=TRUE, prior.plots=FALSE)
met_norm <- data.frame(colnames(met_norm), t(met_norm)); colnames(met_norm)[1] <- "Subject_ID"

batch_combat <- merge(batch, met_norm, by = "Subject_ID")
batch_pca <- prcomp(batch_combat[,3:ncol(batch_combat)], center = T, scale. = T)
ggbiplot::ggbiplot(batch_pca, ellipse=FALSE,  groups=batch_combat$Batch, var.axes = F)

batch_cor <- data.frame(PCs = colnames(batch_pca$x[,1:5]))
batch_cor$corr <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_combat$Batch)))$estimate)
batch_cor$P_value <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_combat$Batch)))$p.value)

batch_cor
```

Control for batch effect by normalization by reference feature trifluoromethanosulfate.

This method didn't work well. Couldn't fully adjust for batch effect, and highly correlated data.

```{r , echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
CompNorm<-function(x, ref){
  10E9*x/x[ref];
}

met_norm<-t(apply(met_impute[,-1], 1, CompNorm, "trifluoromethanosulfate"))
met_norm <- data.frame(met_impute$Subject_ID, met_norm); colnames(met_norm)[1] <- "Subject_ID"
met_norm <- subset(met_norm, select = -c(trifluoromethanosulfate))

# batch <- read.xlsx(file = "/Users/qiyan/Dropbox/PARENTs/Input/met_129_metaboanalyst.xlsx", sheetIndex = 1, header = T); batch <- batch[,1:2]
batch_ref <- merge(batch, met_norm, by = "Subject_ID")
batch_pca <- prcomp(batch_ref[,3:ncol(batch_ref)], center = F, scale. = F)

batch_cor <- data.frame(PCs = colnames(batch_pca$x[,1:5]))
batch_cor$corr <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_ref$Batch)))$estimate)
batch_cor$P_value <- apply(batch_pca$x[,1:5], 2, function(x) cor.test(x, as.numeric(as.factor(batch_ref$Batch)))$p.value)

batch_cor
```

### Transformation

Conduct generalized logarithm transformation.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
LogNorm<-function(x, min.val){
  log2((x + sqrt(x^2 + min.val^2))/2)
}
min.val <- halfdatmin/5
met_trans <- data.frame(cbind(met_norm$Subject_ID, apply(met_norm[,-1], 2, LogNorm, min.val))); colnames(met_trans)[1] <- "Subject_ID"
met_trans[,-1] <- apply(met_trans[,-1], 2, function(x) as.numeric(x))
```

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 15, fig.width = 15}
ggplot(stack(met_trans[,-1]), aes(x = values, y = ind, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Distribution of the raw intensity of metabolites', x = "Intensity", y = "Metabolites") +
  theme_ipsum() +
  theme(
    legend.position="none",
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  )
```

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
# Save data: met_norm - correct for batches, but not log transformation; met_trans - log transformation
save(met_norm, met_trans, pheno, nut, met_class, file = "/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_trans.RData")
```

# Data Mining

## Metabolites

### Correlation between metabolites

```{r , echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
load("/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_trans.RData")

met_corr <- met_trans[,-1]
met_corr <- met_corr[,order(colnames(met_corr))]

met_corr <- cor(met_corr)
annotation_col <- met_class[which(met_class$Met_ID %in% colnames(met_corr)), -2]; annotation_col <- annotation_col[order(annotation_col$Met_ID),]
rownames(annotation_col) <- annotation_col$Met_ID; annotation_col <- subset(annotation_col, select = -c(Met_ID))

colors <- rev(colorRampPalette(RColorBrewer::brewer.pal(10, "RdBu"))(256))
pheatmap::pheatmap(mat = met_corr, fontsize=12, fontsize_row=12, color = colors, annotation_col = annotation_col)
```

![heatmap](/Users/qiyan/Dropbox/PARENTs/Output/heatmap_metabolites.PNG)

## Metabolites - Phenotypes

Only 126 subjects have pheno data, so restricted to 126 subjects.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
load("/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_trans.RData")
met_pheno_input <- met_trans[which(rownames(met_trans) %in% pheno$Subject_ID), -1]
met_pheno_input <- met_pheno_input[,order(colnames(met_pheno_input))]
met_pheno_input_untrans <- met_norm[which(rownames(met_norm) %in% pheno$Subject_ID), -1]
met_pheno_input_untrans <- met_pheno_input_untrans[,order(colnames(met_pheno_input_untrans))]

# split pheno dataset into numeric and character ones
pheno_numeric <- select_if(pheno, is.numeric)
pheno_char <- select_if(pheno, is.character)
```

### PCA analysis

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
# Use non-transformed data matrix, center and scale = T
pca <- prcomp(met_pheno_input_untrans, center = T, scale. = T)
summary(pca)
pca_score <- data.frame(pca$x[,1:10])

ggbiplot::ggbiplot(pca, ellipse=FALSE, var.axes = T) +
  labs(title = "PCA plot of metabolites")
```

Plot the loadings of PCs.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 12, fig.width = 12}
pca_loading <- pca$rotation

annotation_col <- met_class[which(met_class$Met_ID %in% rownames(pca_loading)), -2]; annotation_col <- annotation_col[order(annotation_col$Met_ID),]
rownames(annotation_col) <- annotation_col$Met_ID; annotation_col <- subset(annotation_col, select = -c(Met_ID))

colors <- rev(colorRampPalette(RColorBrewer::brewer.pal(10, "RdBu"))(256))
pheatmap::pheatmap(mat = pca_loading[,1:10], fontsize=12, fontsize_row=12, color = colors, annotation_row = annotation_col, cluster_cols = F, cellwidth = 25, cellheight = 12
)
```

#### ANOVA test: PC scores with categorical variables

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
anova <- data.frame(pca_score, pheno_char)
anova[anova == ""] <- NA
anova <- anova[,-c(11,12,18:22,29,30)]

anova_summary <- data.frame(colnames(anova), PC1 = 1, PC2 = 1, PC3 = 1, PC4 = 1, PC5 = 1, PC6 = 1, PC7 = 1, PC8 = 1, PC9 = 1, PC10 = 1)

for (i in 1:10) {
  for (j in c(11:ncol(anova))){
    anova_summary[j,i+1] <- summary(aov(anova[,i] ~ anova[,j], data = anova, na.action = na.exclude))[[1]][["Pr(>F)"]][1]
  }
}

anova_summary <- anova_summary[-c(1:10),]

significant_variable_cat <- {}
for (i in 1:nrow(anova_summary)) {
  if(sum(anova_summary[i,] < 0.05) > 0){
    temp <- anova_summary[i,1]
    significant_variable_cat <- cbind(significant_variable_cat, temp)
  }
}

print("Categorical variables significanly associated with PC1 - PC10")
as.vector(significant_variable_cat)
```

```{r, echo=FALSE}
library(shiny)

pheno_char_shiny <- anova[,-c(1:10)]

shinyApp(

  ui = fluidPage(
    selectInput("cov", "Categorical variable:",
                choices = colnames(pheno_char_shiny)),
    plotOutput("pcaPlot")
  ),

  server = function(input, output) {
    output$pcaPlot = renderPlot({
      ggbiplot::ggbiplot(pca, ellipse=FALSE, var.axes = F, groups = pheno_char_shiny[,input$cov]) +
  labs(title = "PCA plot of metabolites")
    })
  },

  options = list(height = 500)
)
```

#### Correlation test: PC scores with numeric variables

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
corr <- pheno_numeric[,-c(24:28)]

corr_summary <- data.frame(colnames(corr), PC1 = 1, PC2 = 1, PC3 = 1, PC4 = 1, PC5 = 1, PC6 = 1, PC7 = 1, PC8 = 1, PC9 = 1, PC10 = 1)

for (i in 1:10) {
  for (j in c(1:ncol(corr))){
    corr_summary[j,i+1] <- cor.test(corr[,j], pca_score[,i], na.action = na.rm)$p.value
  }
}


significant_variable_num <- {}
for (i in 1:nrow(corr_summary)) {
  if(sum(corr_summary[i,] < 0.05) > 0){
    temp <- corr_summary[i,1]
    significant_variable_num <- cbind(significant_variable_num, temp)
  }
}

print("Numeric variables significanly associated with PC1 - PC10")
as.vector(significant_variable_num)
```

```{r, echo=FALSE}
library(shiny)

pheno_num_shiny <- corr

shinyApp(
  
  ui = fluidPage(
    selectInput("cov", "Numeric variable:",
                choices = colnames(pheno_num_shiny)),
    column(6,
           plotOutput("histPlot"),
           verbatimTextOutput("text"))
  ),
  
  server = function(input, output) {
    output$histPlot = renderPlot({
      ggplot(pheno_num_shiny, aes(x=pheno_num_shiny[,input$cov],)) + 
        geom_histogram(colour = "black", fill = "lightseagreen") + 
        geom_rug(aes(y=0),  sides="b", position = "jitter") +
        theme(axis.title.x=element_blank())
    })
    output$text <- renderText({
      paste("Number of missing:", sum(is.na(pheno_num_shiny[,input$cov])))
      paste("Number of missing:", sum(is.na(pheno_num_shiny[,input$cov])), "\nMean:", mean(pheno_num_shiny[,input$cov], na.rm = T), "\nMedian:", median(pheno_num_shiny[,input$cov], na.rm = T))
    })
  },
  
  options = list(height = 500)
)
```

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 6}
num_corr <- cor(corr, pca_score,use = "p")

colors <- rev(colorRampPalette(RColorBrewer::brewer.pal(10, "RdBu"))(256))
pheatmap::pheatmap(mat = num_corr, fontsize=12, fontsize_row=12, color = colors, cluster_cols = F, cellheight = 10)
```

### PhenoMWAS

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
pheno_used <- pheno
rownames(pheno_used) <- pheno_used$Subject_ID
pheno_used <- pheno_used[,which(colnames(pheno_used) %in% c(corr_summary$colnames.corr., anova_summary$colnames.anova.))]
pheno_used[pheno_used == ""] <- NA

PhenoMWAS_summary <- data.frame(); k=1

for (i in 1:ncol(met_pheno_input)) {
  for (j in 1:ncol(pheno_used)) {
    temp <- summary(lm(met_pheno_input[,i] ~ pheno_used[,j]))$coefficients[-1,4]
    if(sum(temp < 0.05) > 0){
      PhenoMWAS_summary[k,1] <- colnames(pheno_used)[j]
      PhenoMWAS_summary[k,2] <- colnames(met_pheno_input)[i]
      k = k + 1
    }
  }
}

colnames(PhenoMWAS_summary) <- c("Pheno", "Metabolite")

PhenoMWAS_summary <- merge(x = PhenoMWAS_summary, y = met_class[,c(1,3)], by.x = "Metabolite", by.y = "Met_ID", all.x = T)
PhenoMWAS_summary <- PhenoMWAS_summary[order(PhenoMWAS_summary$Pheno),]
PhenoMWAS_summary <- PhenoMWAS_summary[,c("Pheno", "Metabolite", "Class")]

PhenoMWAS_summary

unique(PhenoMWAS_summary$Pheno)
unique(PhenoMWAS_summary$Metabolite)
```

## Diets

Only 94 subjects have diet data.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
load("/Users/qiyan/Dropbox/PARENTs/Input/MetDietPheno_129_trans.RData")

nut_used <- nut[,-c(1:6)]
rownames(nut_used) <- nut$PARENTs.ID

print("Number of diets:")
print(dim(nut_used))

head(nut_used)
```

### Missing values

Remove diet variables if everyone = 0;

Check diet variables if perentage of missing >= 0.8.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
print("Variables that everyone is mssing:"); colnames(nut_used[,which(apply(nut_used, 2, function(x) sum(x == 0))/94*100 == 100)])
# Remove 100% missing variables
nut_rmMissing <- nut_used[,-which(apply(nut_used, 2, function(x) sum(x == 0))/94*100 == 100)]

missing <- nut_used[,which(apply(nut_used, 2, function(x) sum(x == 0))/94*100 > 80 & apply(nut_used, 2, function(x) sum(x == 0))/94*100 < 100)]
print("Variable with more than 80% missing:"); colnames(missing)
missing
```

### Distribution and outliers

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, fig.height = 40, fig.width = 15}
ggplot(stack(nut_rmMissing), aes(x = values, y = ind, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Distribution of the raw values of diet variables', x = "Values", y = "Diets") +
  theme_ipsum() +
  theme(
    legend.position="none",
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  )
```

Use 3SD as the threshold of outlier. Create a PDF report.

Notice: for all plots, zero values have been removed.

```{r , echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
pdf(file = "/Users/qiyan/Dropbox/PARENTs/Output/Diet_data_dist.pdf")

# First remove 0 values, and then check for outlier
# Inspired by https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/

data_expo <- function(dt) {
  for (i in 1:ncol(dt)) {
    var_name <- dt[,i]
    na1 <- sum(is.na(var_name))
    # check for 0
    var_missing <- sum(var_name == 0)
    var_name[which(var_name == 0)] <- NA # change 0 to NA
    # mean and sd with outliers
    m1 <- mean(var_name, na.rm = T)
    sd1 <- sd(var_name, na.rm = T)
    par(mfrow=c(2, 2), oma=c(0,0,5,0))
    boxplot(var_name, main="With outliers")
    hist(var_name, main="With outliers", xlab=NA, ylab=NA)
    # Detect outlier
    {
      lowerq = quantile(var_name, na.rm = T)[2]
      upperq = quantile(var_name, na.rm = T)[4]
      iqr = IQR(var_name, , na.rm = T)#Or use IQR(var_name)
      # we identify extreme outliers
      extreme.threshold.upper = (iqr * 3) + upperq
      extreme.threshold.lower = lowerq - (iqr * 3)
      outlier <- which(var_name > extreme.threshold.upper | var_name < extreme.threshold.lower)
      number_outlier <- length(outlier)
    }
    # mean of outlier
    mo <- mean(var_name[outlier])
    var_name[outlier] <- NA
    boxplot(var_name, main="Without outliers")
    hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
    
    title_text <- paste(colnames(dt)[i], "\nNumber of 0s:", var_missing,"\nMean:", round(m1, 2), " SD:", round(sd1, 2), 
                        " Outliers identified:", number_outlier, 
                        "\nMean of the outliers:", round(mo, 2), " Mean if we remove outliers:", round(m2, 2))
    title(title_text, outer=TRUE, line = -1)
  }
}

data_expo(nut_rmMissing)
dev.off()
```

Check how many outliers per subject.

```{r , echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
count_outlier <- function(var_name){
  lowerq = quantile(var_name, na.rm = T)[2]
  upperq = quantile(var_name, na.rm = T)[4]
  iqr = IQR(var_name, , na.rm = T)#Or use IQR(var_name)
  # we identify extreme outliers
  extreme.threshold.upper = (iqr * 3) + upperq
  extreme.threshold.lower = lowerq - (iqr * 3)
  return(var_name > extreme.threshold.upper | var_name < extreme.threshold.lower)
}

missing_matrix <- apply(nut_rmMissing, 2, function(x) count_outlier(x))
rownames(missing_matrix) <- rownames(nut_rmMissing)

print("Subjects with more than 20% outliers:")
names(which(apply(missing_matrix, 1, function(x) sum(x)/dim(nut_rmMissing)[2]*100 > 20)))

print(sum(missing_matrix['PAB81P',])/dim(nut_rmMissing)[2]*100)
print(sum(missing_matrix['PLC79F',])/dim(nut_rmMissing)[2]*100)
```

### transformation and standardization
Heatmap

### Correlation

### PCA


### cluster of subjects


# PC - met



# To do

* Don't have Age and Sex for everyone...
* How to deal with missing values?
* How to deal with outliers? Threshold of outlier?








